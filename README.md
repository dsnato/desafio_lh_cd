# ğŸ¬ Projeto de AnÃ¡lise e Modelagem Preditiva de Notas IMDB

## ğŸ“Œ VisÃ£o Geral
Este projeto tem como objetivo prever a **nota IMDB de filmes** a partir de variÃ¡veis disponÃ­veis em uma base de dados.  
O trabalho inclui **anÃ¡lise exploratÃ³ria (EDA)**, **engenharia de atributos**, **modelagem preditiva** e **boas prÃ¡ticas para evitar data leakage e overfitting**.  

O projeto foi desenvolvido como parte de um desafio tÃ©cnico de CiÃªncia de Dados.  

---

## ğŸ—ï¸ Estrutura do Projeto

â”œâ”€â”€ data/
â”‚ â””â”€â”€ desafio_indicium_imdb.csv # Dataset original
â”œâ”€â”€ notebooks/
â”‚ â””â”€â”€ LH_CD_RENATOSAMICO.ipynb # Notebook com todo o pipeline
â”œâ”€â”€ models/
â”‚ â””â”€â”€ model_imdb_rating.pkl # Modelo treinado (XGBoost)
â”œâ”€â”€ README.md # DocumentaÃ§Ã£o do projeto

---

## ğŸ“Š Fluxo do Projeto

### 1. **AnÃ¡lise ExploratÃ³ria (EDA)**
- DistribuiÃ§Ãµes das variÃ¡veis (`IMDB_Rating`, `Meta_score`).  
- CorrelaÃ§Ã£o de **Pearson** entre variÃ¡veis numÃ©ricas.  
- IdentificaÃ§Ã£o de pares de features altamente correlacionadas (|r| > 0.85).  
- VisualizaÃ§Ã£o dos gÃªneros mais frequentes.  

### 2. **Feature Engineering Seguro**
- **One-hot encoding** de gÃªneros.  
- **ReputaÃ§Ã£o em bins** para diretor e ator principal (`baixo`, `mÃ©dio-baixo`, `mÃ©dio-alto`, `alto`).  
- **MÃ©dia de rating dos 3 principais atores** (Star1â€“Star3).  
- **TransformaÃ§Ãµes logarÃ­tmicas** em `Gross` e `No_of_Votes`.  
- **ValidaÃ§Ã£o visual de cada transformaÃ§Ã£o**: histogramas, countplots e distribuiÃ§Ãµes.  

### 3. **Modelagem**
- Baselines: **RegressÃ£o Linear** e **Random Forest**.  
- Modelo principal: **XGBoost**.  
- MÃ©trica: **RMSE (Root Mean Squared Error)**.  

### 4. **Monitoramento e Robustez**
- **Curvas de aprendizado** para detecÃ§Ã£o de overfitting/underfitting.  
- **ImportÃ¢ncia de features** no XGBoost.  
- **RemoÃ§Ã£o da variÃ¡vel de maior importÃ¢ncia** e re-treino para avaliar resiliÃªncia do modelo.  

---

## âš ï¸ Principais Cuidados

1. **Evitar Data Leakage**  
   - `Meta_score` foi analisado, mas **removido da modelagem**, pois possui correlaÃ§Ã£o muito alta com `IMDB_Rating`.  
   - `Target encoding` direto em atores/diretores foi evitado â€” optamos por **bins de reputaÃ§Ã£o**.  

2. **Controle de Overfitting**  
   - Curvas de aprendizado usadas para comparar desempenho em treino e validaÃ§Ã£o.  
   - ComparaÃ§Ã£o com baselines mostrou se o ganho do XGBoost era legÃ­timo.  

3. **InterpretaÃ§Ã£o de Features**  
   - ImportÃ¢ncia de features analisada criticamente.  
   - Re-treino sem a variÃ¡vel mais importante aumentou a robustez do pipeline.  

---

## ğŸš€ Como Executar o Projeto

### 1. Clonar o repositÃ³rio
```
git clone https://github.com/seu-usuario/projeto-imdb.git
cd projeto-imdb

2. Criar ambiente virtual
python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scripts\activate      # Windows

3. Instalar dependÃªncias
pip install -r requirements.txt

4. Executar o notebook
Abra o Jupyter Notebook:
jupyter notebook
E rode LH_CD_RENATOSAMICO.ipynb.

ğŸ“¦ Principais DependÃªncias
Python 3.9+
pandas, numpy
seaborn, matplotlib
scikit-learn
xgboost
joblib
```

ğŸ“ˆ Resultados
O modelo XGBoost apresentou o menor RMSE comparado aos baselines.
ApÃ³s remover a feature mais importante, o desempenho se manteve estÃ¡vel, mostrando maior resiliÃªncia.
No_of_Votes_log e Gross_log foram confirmadas como variÃ¡veis fortes, junto com os gÃªneros.
