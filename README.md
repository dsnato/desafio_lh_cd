# üé¨ Projeto de An√°lise e Modelagem Preditiva de Notas IMDB

## üìå Vis√£o Geral
Este projeto tem como objetivo prever a **nota IMDB de filmes** a partir de vari√°veis dispon√≠veis em uma base de dados.  
O trabalho inclui **an√°lise explorat√≥ria (EDA)**, **engenharia de atributos**, **modelagem preditiva** e **boas pr√°ticas para evitar data leakage e overfitting**.  

O projeto foi desenvolvido como parte de um desafio t√©cnico de Ci√™ncia de Dados.  

---

## üìä Fluxo do Projeto

### 1. **An√°lise Explorat√≥ria (EDA)**
- Distribui√ß√µes das vari√°veis (`IMDB_Rating`, `Meta_score`).  
- Correla√ß√£o de **Pearson** entre vari√°veis num√©ricas.  
- Identifica√ß√£o de pares de features altamente correlacionadas (|r| > 0.85).  
- Visualiza√ß√£o dos g√™neros mais frequentes.  

### 2. **Feature Engineering Seguro**
- **One-hot encoding** de g√™neros.  
- **Reputa√ß√£o em bins** para diretor e ator principal (`baixo`, `m√©dio-baixo`, `m√©dio-alto`, `alto`).  
- **M√©dia de rating dos 3 principais atores** (Star1‚ÄìStar3).  
- **Transforma√ß√µes logar√≠tmicas** em `Gross` e `No_of_Votes`.  
- **Valida√ß√£o visual de cada transforma√ß√£o**: histogramas, countplots e distribui√ß√µes.  

### 3. **Modelagem**
- Baselines: **Regress√£o Linear** e **Random Forest**.  
- Modelo principal: **XGBoost**.  
- M√©trica: **RMSE (Root Mean Squared Error)**.  

### 4. **Monitoramento e Robustez**
- **Curvas de aprendizado** para detec√ß√£o de overfitting/underfitting.  
- **Import√¢ncia de features** no XGBoost.  
- **Remo√ß√£o da vari√°vel de maior import√¢ncia** e re-treino para avaliar resili√™ncia do modelo.  

---

## ‚ö†Ô∏è Principais Cuidados

1. **Evitar Data Leakage**  
   - `Meta_score` foi analisado, mas **removido da modelagem**, pois possui correla√ß√£o muito alta com `IMDB_Rating`.  
   - `Target encoding` direto em atores/diretores foi evitado ‚Äî optamos por **bins de reputa√ß√£o**.  

2. **Controle de Overfitting**  
   - Curvas de aprendizado usadas para comparar desempenho em treino e valida√ß√£o.  
   - Compara√ß√£o com baselines mostrou se o ganho do XGBoost era leg√≠timo.  

3. **Interpreta√ß√£o de Features**  
   - Import√¢ncia de features analisada criticamente.  
   - Re-treino sem a vari√°vel mais importante aumentou a robustez do pipeline.  

---

## üöÄ Como Executar o Projeto

### 1. Clonar o reposit√≥rio
```
git clone https://github.com/seu-usuario/projeto-imdb.git
cd projeto-imdb

2. Criar ambiente virtual
python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scripts\activate      # Windows

3. Instalar depend√™ncias
pip install -r requirements.txt

4. Executar o notebook
Abra o Jupyter Notebook:
jupyter notebook
E rode LH_CD_RENATOSAMICO.ipynb.

üì¶ Principais Depend√™ncias
Python 3.9+
pandas, numpy
seaborn, matplotlib
scikit-learn
xgboost
joblib
```

## üìà Resultados

- **Desempenho comparativo:**  
  - O **XGBoost** apresentou o melhor RMSE entre os modelos testados (Regress√£o Linear, Random Forest e XGBoost), servindo como modelo principal.  
  - Os modelos baseline (Linear e Random Forest) foram usados como refer√™ncia para validar o ganho real do XGBoost.

- **Impacto da remo√ß√£o da vari√°vel mais importante:**  
  - Identificou-se a *feature* mais importante a partir da import√¢ncia calculada pelo XGBoost.  
  - Ao remover essa vari√°vel e re-treinar o modelo, avaliamos o efeito na generaliza√ß√£o:  
    - **Se o RMSE n√£o aumentar significativamente**, a remo√ß√£o melhora a robustez contra *leakage* sem perda de performance.  
    - **Se o RMSE aumentar bastante**, √© preciso verificar se essa *feature* √© de fato leg√≠tima para uso em produ√ß√£o (ex.: informa√ß√µes s√≥ dispon√≠veis depois do lan√ßamento do filme).

- **Features com maior influ√™ncia:**  
  - `No_of_Votes_log` e `Gross_log` aparecem como vari√°veis fortes, junto com colunas de g√™nero e a agrega√ß√£o de reputa√ß√£o do elenco.  
  - As *bins* de reputa√ß√£o (diretor/ator) ajudaram a capturar sinal hist√≥rico sem expor diretamente o target.

- **Observa√ß√µes gerais:**  
  - A distribui√ß√£o do target (`IMDB_Rating`) tende a ser concentrada (pouca vari√¢ncia), o que exige features informativas e valida√ß√µes rigorosas.  
  - Curvas de aprendizado foram usadas para diagnosticar **overfitting/underfitting** e orientar a escolha de complexidade e regulariza√ß√£o.
  - O projeto dever√° ser revisto e melhorado no futuro.

